{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U py3dti miniaudio soundcard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, radians\n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "from miniaudio import decode_file, SampleFormat\n",
    "import soundcard\n",
    "import py3dti"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup py3dti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = py3dti.BinauralRenderer(rate=44100, buffer_size=512, resampled_angular_resolution=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = renderer.add_listener(position=None, orientation=None, head_radius=0.0875)\n",
    "listener.load_hrtf_from_sofa(f'../3dti_AudioToolkit/resources/HRTF/SOFA/3DTI_HRTF_IRC1008_512s_{renderer.rate}Hz.sofa')\n",
    "# listener.load_hrtf_from_3dti(f'../3dti_AudioToolkit/resources/HRTF/SOFA/3DTI_HRTF_IRC1008_512s_{renderer.rate}Hz.3dti-hrtf') # faster, but less common file format\n",
    "listener.load_ild_near_field_effect_table(f'../3dti_AudioToolkit/resources/ILD/NearFieldCompensation_ILD_{renderer.rate}.3dti-ild')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener.position, listener.orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener.position = (0, 0, 0) # default listener position\n",
    "listener.orientation = (1, 0, 0, 0) # default listener orientation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = renderer.add_environment()\n",
    "environment.load_brir_from_sofa(f'../3dti_AudioToolkit/resources/BRIR/SOFA/3DTI_BRIR_medium_{renderer.rate}Hz.sofa')\n",
    "# environment.load_brir_from_3dti(f'../3dti_AudioToolkit/resources/BRIR/SOFA/3DTI_BRIR_medium_{renderer.rate}Hz.3dti-brir') # faster, but less common file format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add source(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = renderer.add_source(position=(2, 2, 2), orientation=(2, 1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.position, source.orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer, renderer.listener, renderer.sources, renderer.environments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read source samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'../3dti_AudioToolkit/resources/AudioSamples/Anechoic Speech {renderer.rate}.wav'\n",
    "decoded_file = decode_file(filename=file_path, output_format=SampleFormat.FLOAT32,\n",
    "                           nchannels=1, sample_rate=renderer.rate)\n",
    "samples = np.asarray(decoded_file.samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline rendering to `np.array`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering with static listener and sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = {source: samples}\n",
    "binaural_samples = renderer.render_offline(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(binaural_samples.T, rate=renderer.rate, normalize=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rendering with dynamic listener or sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaural_length = np.max(list(map(len, sources.values())))\n",
    "binaural_samples = np.zeros((binaural_length, 2), dtype=np.float32)\n",
    "input_buffer = np.zeros(renderer.buffer_size, dtype=np.float32)\n",
    "\n",
    "for start in np.arange(0, binaural_length, renderer.buffer_size):\n",
    "    block_end = min(start + renderer.buffer_size, binaural_length)\n",
    "    for source, samples in sources.items():\n",
    "        if start < len(samples):\n",
    "            # Comment the next line to keep the sources stationary in the location defined above,\n",
    "            # otherwise it will circle counter-clockwise in the frontal plane\n",
    "            source.position = (0, sin(radians(start/renderer.buffer_size)), cos(radians(start/renderer.buffer_size)))\n",
    "            source_end = min(block_end, len(samples))\n",
    "            source_size = source_end - start\n",
    "            input_buffer[:source_size] = samples[start:source_end]\n",
    "            input_buffer[source_size:] = 0\n",
    "            binaural_samples[start:source_end] += np.column_stack(source.process_anechoic(input_buffer))[:source_size]\n",
    "    block_size = block_end - start\n",
    "    for environment in renderer.environments:\n",
    "        binaural_samples[start:block_end] += np.column_stack(environment.process_virtual_ambisonic_reverb())[:block_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(binaural_samples.T, rate=renderer.rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaural_length = np.max(list(map(len, sources.values())))\n",
    "input_buffer = np.zeros(renderer.buffer_size, dtype=np.float32)\n",
    "output_buffer = np.zeros((renderer.buffer_size, 2), dtype=np.float32)  \n",
    "\n",
    "with soundcard.default_speaker().player(samplerate=renderer.rate, channels=2) as stereo_speaker:\n",
    "    for start in np.arange(0, binaural_length, renderer.buffer_size):\n",
    "        output_buffer.fill(0)\n",
    "        block_end = min(start + renderer.buffer_size, binaural_length)\n",
    "        for source, samples in sources.items():\n",
    "            if start < len(samples):\n",
    "                # Comment the next line to keep the sources stationary in the location defined above,\n",
    "                # otherwise it will circle counter-clockwise in the horizontal plane\n",
    "                source.position = (cos(radians(start/renderer.buffer_size)), sin(radians(start/renderer.buffer_size)), 0)\n",
    "                source_end = min(block_end, len(samples))\n",
    "                source_size = source_end - start\n",
    "                input_buffer[:source_size] = samples[start:source_end]\n",
    "                input_buffer[source_size:] = 0\n",
    "                output_buffer += np.column_stack(source.process_anechoic(input_buffer))\n",
    "        for environment in renderer.environments:\n",
    "            output_buffer += np.column_stack(environment.process_virtual_ambisonic_reverb())\n",
    "        block_size = block_end - start\n",
    "        stereo_speaker.play(output_buffer[:block_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more (modifiable) properties with sensible default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listener.head_radius, listener.ild_attenuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.spatialization_mode, source.anechoic_processing, source.reverb_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.far_distance_effect, source.near_field_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source.propagation_delay, source.anechoic_distance_attenuation, source.anechoic_distance_attenuation_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "593772607564889768e040c4eca06ac0365bf9b661ccbf98b2a603716fd53ed2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
